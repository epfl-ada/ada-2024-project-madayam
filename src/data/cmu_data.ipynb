{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "253256da5d912595",
   "metadata": {},
   "source": [
    "## CMU Movie Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cac758684768c1",
   "metadata": {},
   "source": [
    "### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9998b9f902f4304",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:16:12.037405Z",
     "start_time": "2024-11-14T16:16:12.028075Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from wikimapper import WikiMapper\n",
    "import re\n",
    "import csv\n",
    "import json\n",
    "import ast\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a06e2c650b60632",
   "metadata": {},
   "source": [
    "### Load CMU Movie Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:16:12.056488Z",
     "start_time": "2024-11-14T16:16:12.046847Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_data_path = '../data/MovieSummaries/movie.metadata.tsv'\n",
    "column_names = ['Wikipedia_movie_ID', 'Freebase_movie_ID', 'movie_name', 'movie_year', 'movie_revenue', 'movie_runtime',\n",
    "                'movie_languages', 'movie_countries', 'movie_genres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75389600fd4b2bd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:16:12.532032Z",
     "start_time": "2024-11-14T16:16:12.156582Z"
    }
   },
   "outputs": [],
   "source": [
    "meta_df = pd.read_csv(meta_data_path, sep='\\t', header=None, names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "232f2c855d173736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_string_to_dict(dict_str):\n",
    "    \"\"\"\n",
    "    Attempts to convert a string to a dictionary using json.loads.\n",
    "    If it fails, tries ast.literal_eval.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # First, try using json.loads\n",
    "        return json.loads(dict_str)\n",
    "    except json.JSONDecodeError:\n",
    "        try:\n",
    "            # If json.loads fails, try ast.literal_eval\n",
    "            return ast.literal_eval(dict_str)\n",
    "        except (ValueError, SyntaxError) as e:\n",
    "            # If both methods fail, return None or raise an exception\n",
    "            print(\"Failed to convert string to dictionary:\", e)\n",
    "            return None\n",
    "\n",
    "def map_codes_to_items(list_of_dicts):\n",
    "    \"\"\"\n",
    "    Maps a list of dictionaries to a list of items.\n",
    "    \"\"\"\n",
    "    \n",
    "    map_codes_to_something= {}\n",
    "    for d in list_of_dicts:\n",
    "        for k, v in d.items():\n",
    "            map_codes_to_something[k] = v\n",
    "    map_codes_to_something['nan'] = None\n",
    "    return map_codes_to_something\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a6d9d28ccfe6ba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_countries_codes = []\n",
    "for s in np.array(meta_df[\"movie_countries\"]):\n",
    "    list_countries_codes.append(convert_string_to_dict(s))\n",
    "list_countries = [tuple(sublist.values()) for sublist in list_countries_codes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "5a6ddcd822257212",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_languages_codes = []\n",
    "for s in np.array(meta_df[\"movie_languages\"]):\n",
    "    list_languages_codes.append(convert_string_to_dict(s))\n",
    "list_languages = [set(sublist.values()) for sublist in list_languages_codes]\n",
    "\n",
    "list_genres_codes = []\n",
    "for s in np.array(meta_df[\"movie_genres\"]):\n",
    "    list_genres_codes.append(convert_string_to_dict(s))\n",
    "list_genres = [set(sublist.values()) for sublist in list_genres_codes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "2ebe8f623e405fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# countries = pd.DataFrame(np.array(list_countries))\n",
    "countries = [', '.join(map(str, t)) for t in list_countries]\n",
    "meta_df[\"movie_countries\"] = countries\n",
    "\n",
    "languages = pd.DataFrame([', '.join(list_languages) if list_languages else None for list_languages in list_languages])\n",
    "meta_df[\"movie_languages\"] = languages\n",
    "\n",
    "genres = pd.DataFrame([', '.join(genres) if genres else None for genres in list_genres])\n",
    "meta_df[\"movie_genres\"] = genres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "8fa90040713f969",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df.loc[meta_df[\"movie_name\"] == \"Hunting Season\", \"movie_year\"] = \"2010-12-02\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1308e6082f447923",
   "metadata": {},
   "source": [
    "### Add Wikidata IDs to the CMU Movie Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15b1ebcd1cffae47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:16:12.564687Z",
     "start_time": "2024-11-14T16:16:12.550924Z"
    }
   },
   "outputs": [],
   "source": [
    "wiki_ids = meta_df['Wikipedia_movie_ID'].unique().tolist()\n",
    "mapper = WikiMapper(\"index_enwiki-20190420.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87dc4dd33da258d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:16:15.228791Z",
     "start_time": "2024-11-14T16:16:12.583796Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_wikipedia_id_to_wikidata_id(id_):\n",
    "    wikidata_id = mapper.wikipedia_id_to_id(id_)\n",
    "    return wikidata_id\n",
    "\n",
    "meta_df['wikidata_id'] = meta_df['Wikipedia_movie_ID'].apply(convert_wikipedia_id_to_wikidata_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d5142119cf8e7",
   "metadata": {},
   "source": [
    "### Add plot summaries to the CMU Movie Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6793fb77d820ee1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:23:29.661941Z",
     "start_time": "2024-11-14T16:23:25.955895Z"
    }
   },
   "outputs": [],
   "source": [
    "movie_data_path = '../data/MovieSummaries'\n",
    "\n",
    "def convert_txt_to_csv(input_file_path, output_file_path):\n",
    "    \"\"\"\n",
    "    Converts a text file to a CSV file with two columns: movie_id and movie_summary.\n",
    "    The input file should have each line with movie_id and movie_summary separated by a tab or space.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_file_path: Path to the input text file.\n",
    "    - output_file_path: Path where the output CSV file will be saved.\n",
    "    \"\"\"\n",
    "    # Open the input and output files\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as fin, \\\n",
    "            open(output_file_path, 'w', newline='', encoding='utf-8') as fout:\n",
    "\n",
    "        # Initialize CSV writer\n",
    "        writer = csv.writer(fout)\n",
    "\n",
    "        # Write the header\n",
    "        writer.writerow(['Wikipedia_movie_ID', 'movie_summary'])\n",
    "\n",
    "        # Process each line in the input file\n",
    "        for line_number, line in enumerate(fin, start=1):\n",
    "            # Strip leading/trailing whitespace\n",
    "            line = line.strip()\n",
    "\n",
    "            # Skip empty lines\n",
    "            if not line:\n",
    "                print(f\"Skipping empty line at line number {line_number}.\")\n",
    "                continue\n",
    "\n",
    "            # Use regex to split on the first occurrence of tab or space\n",
    "            # This ensures that the summary can contain spaces or tabs\n",
    "            split_result = re.split(r'\\t| ', line, maxsplit=1)\n",
    "\n",
    "            if len(split_result) == 2:\n",
    "                movie_id, movie_summary = split_result\n",
    "            elif len(split_result) == 1:\n",
    "                # Only movie_id is present, no summary\n",
    "                movie_id = split_result[0]\n",
    "                movie_summary = ''\n",
    "                print(f\"No summary found for movie_id '{movie_id}' at line number {line_number}.\")\n",
    "            else:\n",
    "                # Unexpected format\n",
    "                movie_id = ''\n",
    "                movie_summary = ''\n",
    "                print(f\"Unexpected format at line number {line_number}: '{line}'\")\n",
    "\n",
    "            # Write the row to CSV\n",
    "            writer.writerow([movie_id, movie_summary])\n",
    "\n",
    "\n",
    "convert_txt_to_csv(f'{movie_data_path}/plot_summaries.txt', f'{movie_data_path}/plot_summaries.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e99878",
   "metadata": {},
   "source": [
    "### Characters meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e875be09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load charachter metadata\n",
    "column_names_char = ['Wikipedia_movie_ID', 'Freebase_movie', 'movie_release_date', 'character_name', 'actor_DOB', 'gender', 'height', 'ethnicity', 'actor_name', 'actor_age', 'freebase_map', '1','2']\n",
    "tsv_file_char = 'data/MovieSummaries/character.metadata.tsv'\n",
    "df_chars = pd.read_table(tsv_file_char, sep='\\t', names=column_names_char)\n",
    "df_chars.to_csv('character_metadata.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
