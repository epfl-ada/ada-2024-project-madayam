{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ada_config.config import CONFIG\n",
    "import statsmodels.api as sm\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import networkx as nx\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib import pyplot as plt\n",
    "np.bool = np.bool_\n",
    "from datawig import SimpleImputer\n",
    "import plotly.io as pio\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ],
   "id": "c0400b11bf4cb20a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_movies = pd.read_csv(CONFIG[\"data_path\"] / \"MovieVerse.csv\")",
   "id": "f7fd205b355d21d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_movies.head()",
   "id": "1cad8fc4b60cf7e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_movies['budget'].isna().sum()",
   "id": "eaca318ba768e6a4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_movies.drop(columns=['Wikipedia_movie_ID', 'Freebase_movie_ID', 'movie_name', 'movie_summary', 'tmdb_id', 'imdb_id', 'titleType', 'budget', 'movie_revenue'], inplace=True)",
   "id": "925d7ccbbe715346"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_movies['adult'] = df_movies['adult'].astype(float)",
   "id": "f0e2f61876d9f7e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_movies['crew_popularity_max'] = df_movies[['Director_popularity', 'Writer_popularity', 'Producer_popularity']].max(axis=1)\n",
    "df_movies.drop(columns=['Director_popularity', 'Writer_popularity', 'Producer_popularity'], inplace=True)"
   ],
   "id": "8534b249732be308"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_movies.describe()['crew_popularity_max']",
   "id": "1ba8abc44faeaca9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_movies.drop(columns=['star_4_popularity', 'star_5_popularity'], inplace=True)\n",
    "df_movies['cast_popularity_avg'] = df_movies[['star_1_popularity', 'star_2_popularity', 'star_3_popularity']].mean(axis=1)\n",
    "df_movies.drop(columns=['star_1_popularity', 'star_2_popularity', 'star_3_popularity'], inplace=True)"
   ],
   "id": "f4a7cf40b1099f4e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_movies.describe()['cast_popularity_avg']",
   "id": "4bac6a97af07b3c6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "most_genres = [\"Drama\", \"Comedy\", \"Thriller\", \"Romance\", \"Action\", \"Black-And-White\"]\n",
    "\n",
    "def genres_dummies(row):\n",
    "    if pd.isna(row):\n",
    "        return [None] * len(most_genres)\n",
    "    row = [r.strip() for r in row.split(', ')]\n",
    "    dummies = []\n",
    "    for g in most_genres:\n",
    "        if g in row:\n",
    "            dummies.append(1)\n",
    "        else:\n",
    "            dummies.append(0)\n",
    "    return dummies\n",
    "\n",
    "df_movies[[f'is_{genre}' for genre in most_genres]] = df_movies['movie_genres'].apply(genres_dummies).apply(pd.Series)\n",
    "df_movies.drop(columns='movie_genres', inplace=True)"
   ],
   "id": "81421f1d50f8ee69"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_movies.describe()[[f'is_{genre}' for genre in most_genres]]",
   "id": "7637e12a98b6ecda"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_movies['sentiment_score'] = df_movies[['sentiment_label', 'sentiment_score']].dropna().apply(lambda x: x['sentiment_score'] if x['sentiment_label'] == 'POSITIVE' else 1 - x['sentiment_score'], axis=1)\n",
    "df_movies.drop(columns='sentiment_label', inplace=True)"
   ],
   "id": "19acfe99e27da5de"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_movies.describe()['sentiment_score']",
   "id": "7244c37c31b71d16"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_movies['is_USA_movie'] = df_movies['movie_countries'].dropna().apply(lambda x: 'United States of America' in [country.strip() for country in  x.split(', ')])\n",
    "df_movies['is_USA_movie'] = df_movies['is_USA_movie'].astype(float)\n",
    "df_movies.drop(columns='movie_countries', inplace=True)"
   ],
   "id": "75ce790b0a0bb3e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_movies.describe()['is_USA_movie']",
   "id": "e77a1dfd592a68ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_movies['is_en'] = df_movies['original_language'].dropna().apply(lambda x: x == 'en')\n",
    "df_movies['is_en'] = df_movies['is_en'].astype(float)\n",
    "df_movies.drop(columns='original_language', inplace=True)"
   ],
   "id": "acee052e0957db29"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_movies.describe()['is_en']",
   "id": "c3ee022f795777b2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "df_movies['year_interval'] = pd.cut(df_movies['year'], bins=range(1880, 2031, 10), right=False,\n",
    "                             labels=[f\"{i}-{i+9}\" for i in range(1880, 2030, 10)])\n",
    "df_movies['year_interval'] = df_movies['year_interval'].astype(str)\n",
    "df_movies['year_interval'] = df_movies[['year', 'year_interval']].apply(lambda x: '1888-1919' if x['year'] < 1920 else x['year_interval'], axis=1)\n",
    "df_movies['year_interval'] = df_movies[['year', 'year_interval']].apply(lambda x: '2010-2021' if x['year'] >= 2010 else x['year_interval'], axis=1)\n",
    "df_movies = pd.get_dummies(df_movies, columns=[\"year_interval\"], drop_first=True)\n",
    "\n",
    "df_movies.drop(columns=['year'], inplace=True)"
   ],
   "id": "dc52cf396b3ac4a0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "cols = []\n",
    "for col in df_movies.columns:\n",
    "    if col.startswith('year_interval'):\n",
    "        cols.append(col)\n",
    "df_movies.loc[df_movies['year_interval_nan'], cols] = None\n",
    "df_movies.drop(columns=['year_interval_nan'], inplace=True)"
   ],
   "id": "9d00e9bdae9fe0af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_movies.describe()[[col for col in df_movies.columns if col.startswith('year_interval')]]\n",
   "id": "9d46df6b4803f5b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "nan_df = df_movies.isna()\n",
    "\n",
    "nan_corr = nan_df.corr()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.matshow(nan_corr, cmap='coolwarm', fignum=1)\n",
    "plt.colorbar()\n",
    "plt.xticks(ticks=range(df_movies.shape[1]), labels=df_movies.columns, rotation=90)\n",
    "plt.yticks(ticks=range(df_movies.shape[1]), labels=df_movies.columns)\n",
    "plt.title(\"NaN Correlation Matrix\", pad=20)\n",
    "plt.show()"
   ],
   "id": "cdf3c89f0be7ce32"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "cols = list(df_movies.columns)\n",
    "cols.remove('wikidata_id')\n",
    "imputed_dict = {}\n",
    "for col in cols:\n",
    "    print(col, ':')\n",
    "    c_cols = cols.copy()\n",
    "    c_cols.remove(col)\n",
    "    imputer = SimpleImputer(\n",
    "        input_columns=c_cols,\n",
    "        output_column=col\n",
    "    )\n",
    "    imputer.fit(df_movies)\n",
    "    imputed_dict[col] = imputer.predict(df_movies)[col]\n",
    "\n",
    "for col in cols:\n",
    "    df_movies.loc[df_movies[col].isna(), col] = imputed_dict[col][df_movies[col].isna()]"
   ],
   "id": "80f8a1d355a2f147"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_movies.to_csv(CONFIG[\"data_path\"] / \"regression_data.csv\", index=False)",
   "id": "72b3c15ba4877bbb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Regression",
   "id": "d3a275f8c29b5655"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_movies = pd.read_csv(CONFIG[\"data_path\"] / \"regression_data.csv\")\n",
    "df_remakes_dataset = pd.read_csv(CONFIG[\"data_path\"] / \"remakes.csv\")"
   ],
   "id": "1b86f1c5b28f2948"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_movies['is_remake'] = df_movies[\"wikidata_id\"].isin(df_remakes_dataset[\"remake_wikidata_id\"])\n",
    "df_movies['is_remake'] = df_movies['is_remake'].astype(float)\n",
    "df_movies['has_remake'] = df_movies[\"wikidata_id\"].isin(df_remakes_dataset[\"original_wikidata_id\"])\n",
    "df_movies['has_remake'] = df_movies['has_remake'].astype(float)\n",
    "df_movies.drop(columns=['wikidata_id', 'adult'], inplace=True)"
   ],
   "id": "761bea52761c8e82"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_movies['is_before_1980'] = 1 - df_movies['year_interval_1990-1999'] - df_movies['year_interval_2000-2009'] - df_movies['year_interval_2010-2021'] - df_movies['year_interval_1980-1989']\n",
    "df_movies.drop(columns=[col for col in df_movies.columns if col.startswith('year_interval')], inplace=True)"
   ],
   "id": "e1a15e6eb267c93f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_movies['log_revenue_budget_ratio'] = np.log(df_movies['adjusted_revenue']) - np.log(df_movies['adjusted_budget'])\n",
    "df_movies.drop(columns=['adjusted_revenue'], inplace=True)"
   ],
   "id": "860e405441ffc03"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for col in df_movies.columns:\n",
    "    df_movies[col] = df_movies[col].astype(float)"
   ],
   "id": "8def86bf917bdd22"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "cols = list(df_movies.columns)\n",
    "cat_cols = []\n",
    "non_cat_cols = []\n",
    "for col in cols:\n",
    "    col = col.strip()\n",
    "    if col.startswith('is') or col.startswith('year') or col in ['has_remake', 'adult']:\n",
    "        cat_cols.append(col)\n",
    "    else:\n",
    "        non_cat_cols.append(col)\n",
    "\n",
    "sc_ = StandardScaler()\n",
    "df_movies.loc[:, non_cat_cols] = sc_.fit_transform(df_movies[non_cat_cols])\n",
    "for col in non_cat_cols:\n",
    "    df_movies.loc[df_movies[col].isna(), col] = 0\n",
    "df_movies.dropna(inplace=True)\n"
   ],
   "id": "88cb9fcb07d16b84"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "def plot_significance_plotly(model, path_to_save):\n",
    "    coefficients = model.params\n",
    "    conf_intervals = model.conf_int()\n",
    "    conf_intervals.columns = ['lower', 'upper']\n",
    "\n",
    "    coef_df = pd.concat([coefficients, conf_intervals], axis=1)\n",
    "    coef_df.columns = ['coef', 'lower', 'upper']\n",
    "    coef_df = coef_df[coef_df.index != 'const']\n",
    "\n",
    "    coef_df['significant'] = (coef_df['lower'] > 0) | (coef_df['upper'] < 0)\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for i, row in coef_df.iterrows():\n",
    "        color = 'red' if row['significant'] else 'black'\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[i],\n",
    "                y=[row['coef']],\n",
    "                mode='markers',\n",
    "                marker=dict(size=10, color=color),\n",
    "                name=f'{i} Coef'\n",
    "            )\n",
    "        )\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[i, i],\n",
    "                y=[row['lower'], row['upper']],\n",
    "                mode='lines',\n",
    "                line=dict(color='blue', width=2),\n",
    "                showlegend=False\n",
    "            )\n",
    "        )\n",
    "\n",
    "    fig.add_shape(\n",
    "        type=\"line\",\n",
    "        x0=-0.5,\n",
    "        x1=len(coef_df) - 0.5,\n",
    "        y0=0,\n",
    "        y1=0,\n",
    "        line=dict(color=\"black\", width=1, dash=\"dash\")\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            'text': 'Coefficients and Confidence Intervals',\n",
    "            'x': 0.5,\n",
    "            'xanchor': 'center'\n",
    "        },\n",
    "        xaxis_title='Predictor Variables',\n",
    "        yaxis_title='Coefficient Value',\n",
    "        xaxis=dict(tickvals=list(range(len(coef_df))), ticktext=coef_df.index, tickangle=45),\n",
    "        showlegend=False,\n",
    "        template=\"plotly_white\",\n",
    "        autosize=True,\n",
    "        height=600,\n",
    "        width=800,\n",
    "    )\n",
    "\n",
    "    fig.add_annotation(\n",
    "        xref=\"paper\",\n",
    "        yref=\"paper\",\n",
    "        x=1.15,\n",
    "        y=1.05,\n",
    "        text=\"<br><span style='color:red'>Red = Significant</span><br>Black = Not Significant\",\n",
    "        showarrow=False,\n",
    "        font=dict(size=12),\n",
    "        align=\"left\",\n",
    "        bordercolor=\"black\",\n",
    "        borderwidth=1,\n",
    "        borderpad=5,\n",
    "        bgcolor=\"white\"\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    pio.write_html(fig, path_to_save, auto_open=True, include_plotlyjs=\"cdn\")\n",
    "\n",
    "    return coef_df\n"
   ],
   "id": "7080decfaab635e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def regress(df, has_remake=True):\n",
    "\n",
    "    if has_remake:\n",
    "        col_keep = 'has_remake'\n",
    "        col_remove = 'is_remake'\n",
    "    else:\n",
    "        col_keep = 'is_remake'\n",
    "        col_remove = 'has_remake'\n",
    "\n",
    "    df = df[df[col_remove] == 0]\n",
    "\n",
    "    X = df.drop(columns=['has_remake', 'is_remake'])\n",
    "    y = df[col_keep]\n",
    "    print('number of samples with positive y:', y.sum())\n",
    "\n",
    "    X = X.astype(float)\n",
    "    y = y.astype(float)\n",
    "    X = sm.add_constant(X, has_constant='add')\n",
    "    model = sm.Logit(y, X).fit()\n",
    "\n",
    "    print('acc:', (model.predict(X) > 0.5).eq(y).mean())\n",
    "    print('f1:', f1_score(y, model.predict(X) > 0.5))\n",
    "    print(model.summary())\n",
    "    return model"
   ],
   "id": "4f2e9ca2f721c012"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "has_model = regress(df_movies, has_remake=True)\n",
    "plot_significance_plotly(has_model, 'has_remake.html')"
   ],
   "id": "7b67835935a5c7ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "res_model = regress(df_movies, has_remake=False)\n",
    "plot_significance_plotly(res_model, 'is_remake.html')"
   ],
   "id": "877cbc04298984b8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def plot_ate_or_histograms(results, output_file=\"ate_or_histograms.html\"):\n",
    "\n",
    "    columns = list(results.keys())\n",
    "    try:\n",
    "        ate_values = [results[col]['ATE'] for col in columns]\n",
    "        or_values = [results[col]['OR'] for col in columns]\n",
    "    except KeyError as e:\n",
    "        raise ValueError(f\"Missing expected key in results: {e}\")\n",
    "\n",
    "    if not ate_values or not or_values:\n",
    "        raise ValueError(\"ATE or OR values are empty. Check the input results dictionary.\")\n",
    "\n",
    "    fig_ate = go.Figure()\n",
    "\n",
    "    if ate_values:\n",
    "        fig_ate.add_trace(go.Bar(\n",
    "            x=columns,\n",
    "            y=ate_values,\n",
    "            name=\"ATE\",\n",
    "            marker=dict(color=\"#636EFA\"),\n",
    "            # text=[f\"{val:.3f}\" for val in ate_values],\n",
    "            textposition=\"outside\",\n",
    "            showlegend=False,\n",
    "        ))\n",
    "        ate_std_err = [results[col]['ATE_std_ere'] * 1.96 for col in columns]\n",
    "        fig_ate.add_trace(go.Scatter(\n",
    "            x=columns,\n",
    "            y=ate_values,\n",
    "            mode='markers',\n",
    "            marker=dict(size=10, color='red'),\n",
    "            name=\"ATE 95% CI\",\n",
    "            error_y=dict(\n",
    "                type='data',\n",
    "                array=ate_std_err,\n",
    "                visible=True\n",
    "            ),\n",
    "            showlegend=False,\n",
    "        ))\n",
    "\n",
    "    fig_ate.add_shape(\n",
    "        type=\"line\",\n",
    "        x0=-0.5,\n",
    "        x1=len(columns) - 0.5,\n",
    "        y0=0.05,\n",
    "        y1=0.05,\n",
    "        line=dict(color=\"black\", width=1, dash=\"dash\")\n",
    "    )\n",
    "\n",
    "    fig_ate.add_shape(\n",
    "        type=\"line\",\n",
    "        x0=-0.5,\n",
    "        x1=len(columns) - 0.5,\n",
    "        y0=-0.05,\n",
    "        y1=-0.05,\n",
    "        line=dict(color=\"black\", width=1, dash=\"dash\")\n",
    "    )\n",
    "\n",
    "    fig_ate.update_layout(\n",
    "        title=\"ATE Metrics Across Columns\",\n",
    "        xaxis=dict(title=\"Columns\", tickmode=\"array\", tickvals=list(range(len(columns))), ticktext=columns),\n",
    "        yaxis=dict(title=\"ATE Values\"),\n",
    "        template=\"plotly_white\",\n",
    "        autosize=True,\n",
    "        height=600,\n",
    "        width=800\n",
    "    )\n",
    "\n",
    "    fig_ate.show()\n",
    "    pio.write_html(fig_ate, output_file.replace(\".html\", \"_ate.html\"), auto_open=True, include_plotlyjs=\"cdn\", auto_play=False)\n",
    "\n",
    "    fig_or = go.Figure()\n",
    "\n",
    "    if or_values:\n",
    "        fig_or.add_trace(go.Bar(\n",
    "            x=columns,\n",
    "            y=or_values,\n",
    "            name=\"OR\",\n",
    "            marker=dict(color=\"#EF553B\"),\n",
    "            # text=[f\"{val:.2f}\" for val in or_values],\n",
    "            textposition=\"outside\"\n",
    "        ))\n",
    "\n",
    "    fig_or.update_layout(\n",
    "        title=\"OR Metrics Across Columns\",\n",
    "        xaxis=dict(title=\"Columns\", tickmode=\"array\", tickvals=list(range(len(columns))), ticktext=columns),\n",
    "        yaxis=dict(title=\"OR Values\"),\n",
    "        template=\"plotly_white\",\n",
    "        autosize=True,\n",
    "        height=600,\n",
    "        width=800\n",
    "    )\n",
    "\n",
    "    fig_or.show()\n",
    "    pio.write_html(fig_or, output_file.replace(\".html\", \"_or.html\"), auto_open=True, include_plotlyjs=\"cdn\", auto_play=False)"
   ],
   "id": "8e4d9289c4a9cbd4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def check_each_col_treat(df, has_remake=True):\n",
    "    if has_remake:\n",
    "        col_keep = 'has_remake'\n",
    "        col_remove = 'is_remake'\n",
    "    else:\n",
    "        col_keep = 'is_remake'\n",
    "        col_remove = 'has_remake'\n",
    "\n",
    "    df = df[df[col_remove] == 0].reset_index(drop=True)\n",
    "\n",
    "    X = df.drop(columns=['has_remake', 'is_remake'])\n",
    "    y = df[col_keep].astype('bool')\n",
    "\n",
    "    result = {}\n",
    "    print('number of samples with positive y:', y.sum())\n",
    "    for treat_col in X.columns:\n",
    "        # if 'sentiment' not in treat_col:\n",
    "        #     continue\n",
    "        result[treat_col] = {}\n",
    "        print()\n",
    "        print('##############', treat_col, '##############')\n",
    "        MAX_MATCHING_THRESHOLD = y.std() / y.shape[0] ** 0.5\n",
    "        if len(X[treat_col].value_counts()) == 2:\n",
    "            thr = 0.5\n",
    "        elif 'sentiment' in treat_col:\n",
    "            thr = 0.0\n",
    "        else:\n",
    "            if 'budget' in treat_col:\n",
    "                thr = X[treat_col].mean() + X[treat_col].std() * 2\n",
    "            # elif 'runtime' in treat_col:\n",
    "            #     thr = X[treat_col].mean()\n",
    "            else:\n",
    "                thr = X[treat_col].mean() + X[treat_col].std() * 1.45\n",
    "        treatment = y\n",
    "        covariates = X.drop(columns=treat_col)\n",
    "        model = sm.Logit(treatment, sm.add_constant(covariates, has_constant='add')).fit()\n",
    "        print('thr:', thr, 'MAX_MATCHING_THRESHOLD:', MAX_MATCHING_THRESHOLD)\n",
    "        outcome = df[treat_col] > thr\n",
    "        df[f'{treat_col}_propensity_score'] = model.predict(sm.add_constant(covariates, has_constant='add'))\n",
    "\n",
    "        df[f'{treat_col}_outcome'] = outcome\n",
    "        control_df = df[~treatment]\n",
    "        treatment_df = df[treatment]\n",
    "        G = nx.Graph()\n",
    "        sorted_control_df = control_df.sort_values(by=f'{treat_col}_propensity_score', ascending=True).reset_index(drop=True)\n",
    "        sorted_treatment_df = treatment_df.sort_values(by=f'{treat_col}_propensity_score', ascending=True).reset_index(drop=True)\n",
    "        start_treatment_index = 0\n",
    "        end_treatment_index = 0\n",
    "\n",
    "        ind_dq = deque()\n",
    "        score_dq = deque()\n",
    "        edges = []\n",
    "        for i, row in sorted_control_df.iterrows():\n",
    "            while end_treatment_index < len(sorted_treatment_df) and abs(row[f'{treat_col}_propensity_score'] - sorted_treatment_df[f'{treat_col}_propensity_score'].iloc[end_treatment_index]) < MAX_MATCHING_THRESHOLD:\n",
    "                ind_dq.append(sorted_treatment_df.index[end_treatment_index])\n",
    "                score_dq.append(sorted_treatment_df[f'{treat_col}_propensity_score'].iloc[end_treatment_index])\n",
    "                end_treatment_index += 1\n",
    "            while start_treatment_index < end_treatment_index and abs(row[f'{treat_col}_propensity_score'] - sorted_treatment_df[f'{treat_col}_propensity_score'].iloc[start_treatment_index]) >= MAX_MATCHING_THRESHOLD:\n",
    "                ind_dq.popleft()\n",
    "                score_dq.popleft()\n",
    "                start_treatment_index += 1\n",
    "            i_score = row[f'{treat_col}_propensity_score']\n",
    "            if thr == 0.5:\n",
    "                # sen_thr = 2\n",
    "                sen_thr = 5\n",
    "            else:\n",
    "                if has_remake:\n",
    "                    sen_thr = 5\n",
    "                    # sen_thr = 1.01\n",
    "                else:\n",
    "                    # sen_thr = 1.5\n",
    "                    # sen_thr = 1.01\n",
    "                    sen_thr = 5\n",
    "            for j, score in zip(ind_dq, score_dq):\n",
    "                if 1 / sen_thr <= (i_score / (1 - i_score)) / (score / (1 - score)) <= sen_thr:\n",
    "                    edges.append((j, i + len(sorted_treatment_df)))\n",
    "        random.shuffle(edges)\n",
    "        G.add_edges_from(edges)\n",
    "        nodes = list(sorted_treatment_df.index)\n",
    "        random.shuffle(nodes)\n",
    "        G.add_nodes_from(nodes, bipartite=0)\n",
    "        nodes = [ind_ + len(sorted_treatment_df) for ind_ in range(len(sorted_control_df))]\n",
    "        random.shuffle(nodes)\n",
    "        G.add_nodes_from(nodes, bipartite=1)\n",
    "\n",
    "        matching = nx.bipartite.maximum_matching(G, top_nodes=list(sorted_treatment_df.index))\n",
    "        print(f'{treat_col} matched:', len(matching) // 2)\n",
    "        pairs = [[matching[i] - len(sorted_treatment_df), i] for i in range(len(sorted_treatment_df)) if i in matching]\n",
    "\n",
    "        pairs = np.array(pairs)\n",
    "        y_control = sorted_control_df.loc[pairs[:, 0], f'{treat_col}_outcome'].values\n",
    "        y_treatment = sorted_treatment_df.loc[pairs[:, 1], f'{treat_col}_outcome'].values\n",
    "        ATE_arr = np.array(y_treatment, dtype=float) - np.array(y_control, dtype=float)\n",
    "        treat_socre = sorted_treatment_df.loc[pairs[:, 1], f'{treat_col}_propensity_score'].values\n",
    "        control_score = sorted_control_df.loc[pairs[:, 0], f'{treat_col}_propensity_score'].values\n",
    "        OR_arr = treat_socre / (1 - treat_socre) / (control_score / (1 - control_score))\n",
    "        print(f'{treat_col} matching ATE:', ATE_arr.mean())\n",
    "        OR = np.maximum(1 / OR_arr.min(), OR_arr.max())\n",
    "        print(f'{treat_col} matching OR:', OR)\n",
    "        result[treat_col]['ATE'] = ATE_arr.mean()\n",
    "        result[treat_col]['OR'] = OR\n",
    "        result[treat_col]['ATE_std_ere'] = ATE_arr.std() / (len(ATE_arr) ** 0.5)\n",
    "    return result"
   ],
   "id": "5825cd2eafbfbaa8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "has_res = check_each_col_treat(df_movies, has_remake=True)\n",
    "plot_ate_or_histograms(has_res, 'casual_has_remake.html')"
   ],
   "id": "1a77fc1d820b5ee8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "is_res = check_each_col_treat(df_movies, has_remake=False)\n",
    "plot_ate_or_histograms(is_res, 'casual_is_remake.html')"
   ],
   "id": "8b11c857d05d6b88"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "106c77b3e94830e2"
  }
 ],
 "metadata": {},
 "nbformat": 5,
 "nbformat_minor": 9
}
